{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/summerlong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "nltk.download('stopwords')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('data/obamacare_tw_19_23.csv')\n",
    "yelp = pd.read_csv('data/yelp_true_sample_100k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove links\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove '\\r' and '\\n'\n",
    "    text = text.replace('\\r', '').replace('\\n', '')\n",
    "    \n",
    "    # Tokenize text, ensuring it is not case insensitive\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stop words, words starting with \"@\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Join filtered tokens back into a string\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    \n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "# apply function to 'text' column in yelp_data\n",
    "tweets['Text_Processed'] = tweets['Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "tfidf_vectorizer = joblib.load('models/tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = joblib.load('models/xgboostv1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sampled_index = pd.read_csv('data/tweetmanualsample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79706</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>51295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>47360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>94472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>81154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>67528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  sentiment\n",
       "0    16528          0\n",
       "1    19792          0\n",
       "2    93112          1\n",
       "3    79706          0\n",
       "4    91551          0\n",
       "..     ...        ...\n",
       "195  51295          0\n",
       "196  47360          0\n",
       "197  94472          1\n",
       "198  81154          1\n",
       "199  67528          1\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_sampled_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = tweets_sampled_index['index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sample = tweets.loc[index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sample = tweets_sample.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = tweets_sample.merge(tweets_sampled_index, left_on='index', right_on='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Processed</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16528</td>\n",
       "      <td>1140752233241415682</td>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>@realDonaldTrump So when are you and Republica...</td>\n",
       "      <td>@ realdonaldtrump republicans going `` repeal ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19792</td>\n",
       "      <td>1150786889118617601</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>@BernieSanders FINALLY! YOU ADMIT YOU ARE AT F...</td>\n",
       "      <td>@ berniesanders finally ! admit fault obamacar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93112</td>\n",
       "      <td>1571969173323931658</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>@DeviousKindly @PoliticsCourage @AlonaGutman @...</td>\n",
       "      <td>@ deviouskindly @ politicscourage @ alonagutma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79706</td>\n",
       "      <td>1422150880858501124</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>It’s just like explaining “socialist Obamacare...</td>\n",
       "      <td>’ like explaining “ socialist obamacare ” affo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91551</td>\n",
       "      <td>1554176905892532234</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>@Solja42 @Andie00471 @desmondalan I voted blue...</td>\n",
       "      <td>@ solja42 @ andie00471 @ desmondalan voted blu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>51295</td>\n",
       "      <td>1290104622133125120</td>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>And also he took away ObamaCare right before p...</td>\n",
       "      <td>also took away obamacare right pandemic actual...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>47360</td>\n",
       "      <td>1272391779543846914</td>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>@LGoralska @ErrolWebber @realDonaldTrump @POTU...</td>\n",
       "      <td>@ lgoralska @ errolwebber @ realdonaldtrump @ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>94472</td>\n",
       "      <td>1582065199086850048</td>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>President Biden Announces Fix to Family Glitch...</td>\n",
       "      <td>president biden announces fix family glitch ob...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>81154</td>\n",
       "      <td>1445084919726698506</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>The South Florida Sun Sentinel reports former ...</td>\n",
       "      <td>south florida sun sentinel reports former pres...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>67528</td>\n",
       "      <td>1323070417972744193</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>Enrollment for Obamacare opens today to 12/15/...</td>\n",
       "      <td>enrollment obamacare opens today 12/15/20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                   Id        Date  \\\n",
       "0    16528  1140752233241415682  2019-06-17   \n",
       "1    19792  1150786889118617601  2019-07-15   \n",
       "2    93112  1571969173323931658  2022-09-19   \n",
       "3    79706  1422150880858501124  2021-08-02   \n",
       "4    91551  1554176905892532234  2022-08-01   \n",
       "..     ...                  ...         ...   \n",
       "195  51295  1290104622133125120  2020-08-03   \n",
       "196  47360  1272391779543846914  2020-06-15   \n",
       "197  94472  1582065199086850048  2022-10-17   \n",
       "198  81154  1445084919726698506  2021-10-04   \n",
       "199  67528  1323070417972744193  2020-11-02   \n",
       "\n",
       "                                                  Text  \\\n",
       "0    @realDonaldTrump So when are you and Republica...   \n",
       "1    @BernieSanders FINALLY! YOU ADMIT YOU ARE AT F...   \n",
       "2    @DeviousKindly @PoliticsCourage @AlonaGutman @...   \n",
       "3    It’s just like explaining “socialist Obamacare...   \n",
       "4    @Solja42 @Andie00471 @desmondalan I voted blue...   \n",
       "..                                                 ...   \n",
       "195  And also he took away ObamaCare right before p...   \n",
       "196  @LGoralska @ErrolWebber @realDonaldTrump @POTU...   \n",
       "197  President Biden Announces Fix to Family Glitch...   \n",
       "198  The South Florida Sun Sentinel reports former ...   \n",
       "199  Enrollment for Obamacare opens today to 12/15/...   \n",
       "\n",
       "                                        Text_Processed  sentiment  \n",
       "0    @ realdonaldtrump republicans going `` repeal ...          0  \n",
       "1    @ berniesanders finally ! admit fault obamacar...          0  \n",
       "2    @ deviouskindly @ politicscourage @ alonagutma...          1  \n",
       "3    ’ like explaining “ socialist obamacare ” affo...          0  \n",
       "4    @ solja42 @ andie00471 @ desmondalan voted blu...          0  \n",
       "..                                                 ...        ...  \n",
       "195  also took away obamacare right pandemic actual...          0  \n",
       "196  @ lgoralska @ errolwebber @ realdonaldtrump @ ...          0  \n",
       "197  president biden announces fix family glitch ob...          1  \n",
       "198  south florida sun sentinel reports former pres...          1  \n",
       "199          enrollment obamacare opens today 12/15/20          1  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sample_tfidf = tfidf_vectorizer.transform(merged_df['Text_Processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.36      0.50       135\n",
      "           1       0.39      0.85      0.53        65\n",
      "\n",
      "    accuracy                           0.52       200\n",
      "   macro avg       0.61      0.60      0.51       200\n",
      "weighted avg       0.68      0.52      0.51       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract true labels from the 'sentiment' column\n",
    "true_labels = merged_df['sentiment']\n",
    "\n",
    "# Make predictions\n",
    "predictions = xgboost.predict(tweets_sample_tfidf)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(true_labels, predictions)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC score: 0.6008547008547009\n"
     ]
    }
   ],
   "source": [
    "auc_roc_score = roc_auc_score(true_labels, predictions)\n",
    "\n",
    "print(f\"AUC-ROC score: {auc_roc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['xgb_pred'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Processed</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>xgb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16528</td>\n",
       "      <td>1140752233241415682</td>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>@realDonaldTrump So when are you and Republica...</td>\n",
       "      <td>@ realdonaldtrump republicans going `` repeal ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19792</td>\n",
       "      <td>1150786889118617601</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>@BernieSanders FINALLY! YOU ADMIT YOU ARE AT F...</td>\n",
       "      <td>@ berniesanders finally ! admit fault obamacar...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93112</td>\n",
       "      <td>1571969173323931658</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>@DeviousKindly @PoliticsCourage @AlonaGutman @...</td>\n",
       "      <td>@ deviouskindly @ politicscourage @ alonagutma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79706</td>\n",
       "      <td>1422150880858501124</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>It’s just like explaining “socialist Obamacare...</td>\n",
       "      <td>’ like explaining “ socialist obamacare ” affo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91551</td>\n",
       "      <td>1554176905892532234</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>@Solja42 @Andie00471 @desmondalan I voted blue...</td>\n",
       "      <td>@ solja42 @ andie00471 @ desmondalan voted blu...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>51295</td>\n",
       "      <td>1290104622133125120</td>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>And also he took away ObamaCare right before p...</td>\n",
       "      <td>also took away obamacare right pandemic actual...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>47360</td>\n",
       "      <td>1272391779543846914</td>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>@LGoralska @ErrolWebber @realDonaldTrump @POTU...</td>\n",
       "      <td>@ lgoralska @ errolwebber @ realdonaldtrump @ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>94472</td>\n",
       "      <td>1582065199086850048</td>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>President Biden Announces Fix to Family Glitch...</td>\n",
       "      <td>president biden announces fix family glitch ob...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>81154</td>\n",
       "      <td>1445084919726698506</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>The South Florida Sun Sentinel reports former ...</td>\n",
       "      <td>south florida sun sentinel reports former pres...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>67528</td>\n",
       "      <td>1323070417972744193</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>Enrollment for Obamacare opens today to 12/15/...</td>\n",
       "      <td>enrollment obamacare opens today 12/15/20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                   Id        Date  \\\n",
       "0    16528  1140752233241415682  2019-06-17   \n",
       "1    19792  1150786889118617601  2019-07-15   \n",
       "2    93112  1571969173323931658  2022-09-19   \n",
       "3    79706  1422150880858501124  2021-08-02   \n",
       "4    91551  1554176905892532234  2022-08-01   \n",
       "..     ...                  ...         ...   \n",
       "195  51295  1290104622133125120  2020-08-03   \n",
       "196  47360  1272391779543846914  2020-06-15   \n",
       "197  94472  1582065199086850048  2022-10-17   \n",
       "198  81154  1445084919726698506  2021-10-04   \n",
       "199  67528  1323070417972744193  2020-11-02   \n",
       "\n",
       "                                                  Text  \\\n",
       "0    @realDonaldTrump So when are you and Republica...   \n",
       "1    @BernieSanders FINALLY! YOU ADMIT YOU ARE AT F...   \n",
       "2    @DeviousKindly @PoliticsCourage @AlonaGutman @...   \n",
       "3    It’s just like explaining “socialist Obamacare...   \n",
       "4    @Solja42 @Andie00471 @desmondalan I voted blue...   \n",
       "..                                                 ...   \n",
       "195  And also he took away ObamaCare right before p...   \n",
       "196  @LGoralska @ErrolWebber @realDonaldTrump @POTU...   \n",
       "197  President Biden Announces Fix to Family Glitch...   \n",
       "198  The South Florida Sun Sentinel reports former ...   \n",
       "199  Enrollment for Obamacare opens today to 12/15/...   \n",
       "\n",
       "                                        Text_Processed  sentiment  xgb_pred  \n",
       "0    @ realdonaldtrump republicans going `` repeal ...          0         0  \n",
       "1    @ berniesanders finally ! admit fault obamacar...          0         1  \n",
       "2    @ deviouskindly @ politicscourage @ alonagutma...          1         0  \n",
       "3    ’ like explaining “ socialist obamacare ” affo...          0         0  \n",
       "4    @ solja42 @ andie00471 @ desmondalan voted blu...          0         1  \n",
       "..                                                 ...        ...       ...  \n",
       "195  also took away obamacare right pandemic actual...          0         1  \n",
       "196  @ lgoralska @ errolwebber @ realdonaldtrump @ ...          0         1  \n",
       "197  president biden announces fix family glitch ob...          1         1  \n",
       "198  south florida sun sentinel reports former pres...          1         1  \n",
       "199          enrollment obamacare opens today 12/15/20          1         0  \n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = joblib.load('models/randomforestv2.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.01       135\n",
      "           1       0.33      1.00      0.49        65\n",
      "\n",
      "    accuracy                           0.33       200\n",
      "   macro avg       0.66      0.50      0.25       200\n",
      "weighted avg       0.78      0.33      0.17       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions2 = randomforest.predict(tweets_sample_tfidf)\n",
    "\n",
    "report2 = classification_report(true_labels, predictions2)\n",
    "\n",
    "print(report2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC score: 0.5037037037037038\n"
     ]
    }
   ],
   "source": [
    "auc_roc_score2 = roc_auc_score(true_labels, predictions2)\n",
    "\n",
    "print(f\"AUC-ROC score: {auc_roc_score2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['rf_pred'] = predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 65910 features, but LogisticRegression is expecting 66095 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m logisticregression \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mmodels/best_logistic_clf.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m predictions3 \u001b[39m=\u001b[39m logisticregression\u001b[39m.\u001b[39;49mpredict(tweets_sample_tfidf)\n\u001b[1;32m      5\u001b[0m report3 \u001b[39m=\u001b[39m classification_report(true_labels, predictions3)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(report3)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_base.py:419\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[39mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m xp, _ \u001b[39m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 419\u001b[0m scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    421\u001b[0m     indices \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_base.py:400\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    397\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    398\u001b[0m xp, _ \u001b[39m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 400\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    401\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    402\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39mreshape(scores, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 588\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    590\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 65910 features, but LogisticRegression is expecting 66095 features as input."
     ]
    }
   ],
   "source": [
    "logisticregression = joblib.load('models/best_logistic_clf.pkl')\n",
    "\n",
    "predictions3 = logisticregression.predict(tweets_sample_tfidf)\n",
    "\n",
    "report3 = classification_report(true_labels, predictions3)\n",
    "\n",
    "print(report3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.43      0.56       135\n",
      "           1       0.40      0.80      0.54        65\n",
      "\n",
      "    accuracy                           0.55       200\n",
      "   macro avg       0.61      0.61      0.55       200\n",
      "weighted avg       0.68      0.55      0.55       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = joblib.load('models/best_svm.pkl')\n",
    "\n",
    "predictions4 = svm.predict(tweets_sample_tfidf)\n",
    "\n",
    "report4 = classification_report(true_labels, predictions4)\n",
    "\n",
    "print(report4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC score: 0.6148148148148148\n"
     ]
    }
   ],
   "source": [
    "auc_roc_score4 = roc_auc_score(true_labels, predictions4)\n",
    "\n",
    "print(f\"AUC-ROC score: {auc_roc_score4}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['svm_pred'] = predictions4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__randomstate_ctor() takes from 0 to 1 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m neural_net \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mmodels/neural_net.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m predictions5 \u001b[39m=\u001b[39m neural_net\u001b[39m.\u001b[39mpredict(tweets_sample_tfidf)\n\u001b[1;32m      5\u001b[0m report5 \u001b[39m=\u001b[39m classification_report(true_labels, predictions5)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/joblib/numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    656\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 658\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[1;32m    659\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/joblib/numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    578\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[1;32m    579\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[1;32m    583\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1213\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1214\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[1;32m   1215\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.3/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:1590\u001b[0m, in \u001b[0;36m_Unpickler.load_reduce\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1588\u001b[0m args \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39mpop()\n\u001b[1;32m   1589\u001b[0m func \u001b[39m=\u001b[39m stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m-> 1590\u001b[0m stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n",
      "\u001b[0;31mTypeError\u001b[0m: __randomstate_ctor() takes from 0 to 1 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "neural_net = joblib.load('models/neural_net.pkl')\n",
    "\n",
    "predictions5 = neural_net.predict(tweets_sample_tfidf)\n",
    "\n",
    "report5 = classification_report(true_labels, predictions5)\n",
    "\n",
    "print(report5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('tweets_with_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
