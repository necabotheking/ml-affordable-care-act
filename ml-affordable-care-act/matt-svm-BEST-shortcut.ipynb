{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Data: Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#suppress warnings\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "#Different attempts to suppress ConvergenceWarning when max_iter terminates\n",
    "#before total model convergence\n",
    "#https://stackoverflow.com/questions/53784971/how-to-disable-convergencewarning-using-sklearn\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "ConvergenceWarning('ignore')\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL PIPELINE CODE BELOW BY: Summer Long\n",
    "#Added and modified print statements somewhat to fit into single cell\n",
    "\n",
    "# run this just in case\n",
    "#nltk.download('all')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process and run TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing yelp data text...\n",
      "Creating binary category based on star rating...\n",
      "Binary category complete\n",
      "\n",
      "The positive class rate is: 76.912\n",
      "The negative class rate is: 23.087999999999994\n",
      "\n",
      "Splitting into train and test data...\n",
      "Training data = 0.8, test data = 0.2\n",
      "Applying TF-IDF vectorizer to training data...\n",
      "Applying TF-IDF vector to test data...\n",
      "Pipeline complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Summer Long code ct'd. \n",
    "\n",
    "# some models are tolerant of class imbalance\n",
    "# also, the other dataset is now imbalanced due to category selection\n",
    "# might as well use the naturally imbalanced one\n",
    "yelp_data = pd.read_csv(\"yelp_true_sample_100k.csv\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # tokenizing test, ensuring it is not case insensitive\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    \n",
    "    # removing stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # joining filtered tokens back into a string\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    \n",
    "    return filtered_text\n",
    "\n",
    "# apply function to 'text' column in yelp_data\n",
    "print(\"Pre-processing yelp data text...\")\n",
    "yelp_data['text'] = yelp_data['text'].apply(preprocess_text)\n",
    "\n",
    "# create binary category based on star rating\n",
    "print(\"Creating binary category based on star rating...\")\n",
    "yelp_data['sentiment'] = yelp_data['stars'].apply(lambda x: 0 if x <= 2 else 1)\n",
    "print(\"Binary category complete\")\n",
    "\n",
    "#positive class rate\n",
    "positive_class_rate = (yelp_data['sentiment'].sum()/100000) * 100\n",
    "print(f\"\\nThe positive class rate is: {positive_class_rate}\")\n",
    "\n",
    "#negative class rate\n",
    "negative_class_rate = 100 - (yelp_data['sentiment'].sum()/100000) * 100\n",
    "print(f\"The negative class rate is: {negative_class_rate}\\n\")\n",
    "\n",
    "# Splitting into train/test with 80/20 split\n",
    "TEST_SIZE = 0.2\n",
    "print(\"Splitting into train and test data...\")\n",
    "print(f\"Training data = {1 - TEST_SIZE}, test data = {TEST_SIZE}\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(yelp_data['text'], \n",
    "                                                    yelp_data['sentiment'], \n",
    "                                                    test_size=TEST_SIZE, \n",
    "                                                    random_state=123)\n",
    "\n",
    "print(\"Applying TF-IDF vectorizer to training data...\")\n",
    "# Define TF-IDF vectorizer and fit to the training data\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "print(\"Applying TF-IDF vector to test data...\")\n",
    "# Transform testing data using the same vectorizer to prevent data leakage\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Pipeline complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x65910 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 899405 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking size of the object\n",
    "\n",
    "X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM].........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 10000\n",
      "obj = -9051.592134, rho = -0.550468\n",
      "nSV = 17756, nBSV = 10578\n",
      "Total nSV = 17756\n",
      ".........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 10000\n",
      "obj = -9077.576950, rho = -0.544317\n",
      "nSV = 17807, nBSV = 10718\n",
      "Total nSV = 17807\n",
      ".........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 10000\n",
      "obj = -8975.722721, rho = -0.562294\n",
      "nSV = 17710, nBSV = 10451\n",
      "Total nSV = 17710\n",
      ".........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 10000\n",
      "obj = -9103.715108, rho = -0.541533\n",
      "nSV = 17816, nBSV = 10747\n",
      "Total nSV = 17816\n",
      ".........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 10000\n",
      "obj = -9034.102587, rho = -0.327828\n",
      "nSV = 17735, nBSV = 10534\n",
      "Total nSV = 17735\n",
      ".........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 10000\n",
      "obj = -10710.578558, rho = 0.505837\n",
      "nSV = 19022, nBSV = 13951\n",
      "Total nSV = 19022\n",
      "Accuracy: 0.92375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83      4669\n",
      "           1       0.94      0.96      0.95     15331\n",
      "\n",
      "    accuracy                           0.92     20000\n",
      "   macro avg       0.90      0.88      0.89     20000\n",
      "weighted avg       0.92      0.92      0.92     20000\n",
      "\n",
      "AUC-ROC: 0.9680599891263589\n"
     ]
    }
   ],
   "source": [
    "# Use best hyperparameters from grid search (other file) \n",
    "#to create the best SVM classifier\n",
    "#Manually inputted so you can skip the grid search\n",
    "best_svc = SVC(C=1.0,\n",
    "               gamma='scale',\n",
    "               kernel='rbf',\n",
    "               max_iter=10000,\n",
    "               probability=True,\n",
    "               verbose=True)\n",
    "\n",
    "# Fit the best SVC to the training data\n",
    "best_svc.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict sentiment of the testing data with model\n",
    "y_pred = best_svc.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate the raw accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# create and print classification report of model\n",
    "# this allows us to evaluate the performance of both classes\n",
    "# this is important due to class imbalance\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# predict probabilities for the test data using the SVC classifier\n",
    "#TODO: Determine whether this is apposite or another method is needed\n",
    "y_pred_proba = best_svc.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# calculate the AUC-ROC metric\n",
    "# this is valuable due to class imbalance\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC-ROC: {auc_roc}\")\n",
    "\n",
    "#RUNTIME: 51m 49s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_svm.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dump model so it can be reloaded\n",
    "import joblib\n",
    "joblib.dump(best_svc, 'best_svm.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full model readout:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Hyperparameters:\n",
    "#{'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 10000}\n",
    "\n",
    "# Accuracy: 0.92375\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.86      0.81      0.83      4669\n",
    "#            1       0.94      0.96      0.95     15331\n",
    "\n",
    "#     accuracy                           0.92     20000\n",
    "#    macro avg       0.90      0.88      0.89     20000\n",
    "# weighted avg       0.92      0.92      0.92     20000\n",
    "\n",
    "# AUC-ROC: 0.9680602266214099"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
